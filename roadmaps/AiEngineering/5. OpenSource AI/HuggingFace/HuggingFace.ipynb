{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hugging Face\n",
    "\n",
    "Source: Official documentation from `https://huggingface.co/learn/llm-course/en/chapter1/6`\n",
    "\n",
    "## LLMs\n",
    "\n",
    "LLMs limitations:\n",
    "* Hallucinations: They can generate incorrect information confidently\n",
    "* Lack of true understanding: They lack true understanding of the world and operate purely on statistical patterns\n",
    "* Bias: They may reproduce biases present in their training data or inputs.\n",
    "* Context windows: They have limited context windows (though this is improving)\n",
    "* Computational resources: They require significant computational resources\n",
    "\n",
    "## Transformers\n",
    "\n",
    "Transformer models are used to solve all kinds of tasks across different modalities, including natural language processing (NLP), computer vision, audio processing, and more.\n",
    "\n",
    "The 🤗 Transformers library provides the functionality to create and use those shared models.\n",
    "\n",
    "\n",
    "The most basic object in the 🤗 Transformers library is the pipeline() function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:\n"
   ],
   "id": "64c18fffb136000a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-30T08:39:34.876310Z",
     "start_time": "2025-08-30T08:39:16.433850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install transformers\n",
    "!pip install transformers[sentencepiece]\n",
    "!pip install \"transformers[sentencepiece]\"\n",
    "!pip install torch"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (4.56.0)\r\n",
      "Requirement already satisfied: filelock in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (3.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (0.34.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (2025.8.29)\r\n",
      "Requirement already satisfied: requests in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (0.22.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\r\n",
      "zsh:1: no matches found: transformers[sentencepiece]\r\n",
      "Requirement already satisfied: transformers[sentencepiece] in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (4.56.0)\r\n",
      "Requirement already satisfied: filelock in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.34.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (2025.8.29)\r\n",
      "Requirement already satisfied: requests in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.22.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.6.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (4.67.1)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.2.1)\r\n",
      "Requirement already satisfied: protobuf in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from transformers[sentencepiece]) (6.32.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (2025.7.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.1.9)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (2025.8.3)\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.8.0-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from torch) (3.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from torch) (4.15.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch)\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: jinja2 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from torch) (2025.7.0)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Downloading torch-2.8.0-cp310-none-macosx_11_0_arm64.whl (73.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.6/73.6 MB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, sympy, networkx, torch\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4/4\u001B[0m [torch]32m3/4\u001B[0m [torch]kx]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.8.0\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T08:43:26.701308Z",
     "start_time": "2025-08-30T08:42:57.694616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ],
   "id": "803b7bfaa64422f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T08:44:02.053270Z",
     "start_time": "2025-08-30T08:44:01.771781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ],
   "id": "f6d1f3e2d8a1ce1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
       " {'label': 'NEGATIVE', 'score': 0.9966409206390381}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 📝 Text Pipelines\n",
    "\n",
    "- **text-generation**\n",
    "  Generate text from a given prompt.\n",
    "  Example: autocomplete a sentence or create creative text.\n",
    "\n",
    "- **text-classification**\n",
    "  Classify text into predefined categories.\n",
    "  Example: sentiment analysis.\n",
    "\n",
    "- **summarization**\n",
    "  Create a shorter version of a text while keeping the key information.\n",
    "\n",
    "- **translation**\n",
    "  Translate text from one language to another.\n",
    "\n",
    "- **zero-shot-classification**\n",
    "  Classify text into labels provided at runtime, without task-specific training.\n",
    "\n",
    "- **feature-extraction**\n",
    "  Extract vector representations (embeddings) from text for downstream tasks such as semantic search.\n",
    "\n",
    "---\n",
    "\n",
    "## 🖼️ Image Pipelines\n",
    "\n",
    "- **image-to-text**\n",
    "  Generate textual descriptions of images (image captioning).\n",
    "\n",
    "- **image-classification**\n",
    "  Identify and classify objects in an image.\n",
    "\n",
    "- **object-detection**\n",
    "  Locate and identify objects in images (bounding boxes + labels).\n",
    "\n",
    "---\n",
    "\n",
    "## 🎙️ Audio Pipelines\n",
    "\n",
    "- **automatic-speech-recognition**\n",
    "  Convert spoken audio into text (speech-to-text).\n",
    "\n",
    "- **audio-classification**\n",
    "  Classify audio recordings into categories (music, noise, sound type, etc.).\n",
    "\n",
    "- **text-to-speech**\n",
    "  Convert text into spoken audio.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔀 Multimodal Pipelines\n",
    "\n",
    "- **image-text-to-text**\n",
    "  Respond to an image based on a text prompt (e.g., visual question answering)."
   ],
   "id": "8ad906cc4cefbb54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot classification\n",
    "**Zero-shot classification** allows a model to assign text to categories it was never explicitly trained on, by leveraging natural language understanding and label descriptions."
   ],
   "id": "497644180f6d5d5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T08:49:37.598121Z",
     "start_time": "2025-08-30T08:47:54.741667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ],
   "id": "cfb50cc4d8b425d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445961475372314, 0.11197615414857864, 0.04342764988541603]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text Generation",
   "id": "bd366a9ed626c909"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T08:50:48.639222Z",
     "start_time": "2025-08-30T08:49:53.022966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# by default is gpt 2\n",
    "classifier = pipeline(\"text-generation\")\n",
    "classifier(\"In this course, we will teach you how to\")"
   ],
   "id": "f1a2fd58c67de2ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to use your smartphone to share all of your favorite social media posts, share your favorite photos, share your favourite videos, and more. We will also show you how to share your YouTube videos, and how to share your YouTube videos with other people.\\n\\nWe will also show you how to share your Facebook videos, and how to share your Facebook videos with other people.\\n\\nWe will show you how to share your YouTube videos, and how to share your YouTube videos with other people.\\n\\nWe will show you how to share your Instagram videos, and how to share your Instagram videos with other people.\\n\\nWe will show you how to share your Twitter posts, and how to share your Twitter posts with other people.\\n\\nWe will show you how to share your Instagram videos, and how to share your Instagram videos with other people.\\n\\nWe will show you how to share your Facebook videos, and how to share your Facebook videos with other people.\\n\\nWe will show you how to share your YouTube videos, and how to share your YouTube videos with other people.\\n\\nWe will show you how to share your YouTube videos, and how to share your YouTube videos with other people.\\n\\nWe will show you how to share your Instagram videos, and'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using any model from the Hub in a pipeline\n",
    "\n",
    "Go to the [Model Hub](https://huggingface.co/models) and click on the corresponding tag on the left to display only the supported models for that task."
   ],
   "id": "47ee61cad00f37ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:02:36.110196Z",
     "start_time": "2025-08-30T09:00:58.273580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ],
   "id": "e0e51c81609052b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to think with a problem-solving mindset that will improve your academic performance. We offer you a wide range of academic subjects to cover, and we will help you practice and develop the skills you need to achieve your goals.\\n\\nWhat are the 4 main steps of the problem solving process?\\n\\nThe Four Steps of the Problem Solving Process: Identify the Problem, Create a Plan, Evaluate the Plan, and Implement the Plan.\\n\\nWhat are the 4 types of problem solving?\\n\\nThe four most common types of problem solving are: Analytical, which focuses on finding solutions to specific problems. Creative, which considers all possible solutions to a problem.\\n\\nWhat is the purpose of problem solving?\\n\\nThe purpose of problem solving is to find a solution to a problem that has been identified by the individual. Problem solving can be used to solve a number of different issues, including, but not limited to, managing a project, creating a new product, and improving an existing product.\\n\\nWhat are the different types of problem solving?\\n\\nThere are four types of problem solving: analytical, creative, integrative, and critical.\\n\\nHow do you solve a problem?\\n\\nThere are four steps to solving a problem: Identify the problem, Brainstorm solutions'},\n",
       " {'generated_text': 'In this course, we will teach you how to use Python to solve real-world problems. We will start with the basics of programming, gradually building up to more advanced concepts. Along the way, we will use Python to solve problems related to data science, machine learning, and artificial intelligence. By the end of this course, you will have a solid understanding of how to use Python to solve complex problems and make sense of the world around you.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:14:01.187556Z",
     "start_time": "2025-08-30T09:13:50.406797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-135M-Instruct\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ],
   "id": "da565cec718c6001",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"I'm a helpful AI assistant named SmolLM, a Linguistic Modeler and a Grammar Modeler. I'm here to help you refine your writing, improve your grammar and syntax, and make your writing more concise and engaging. I can assist with grammar, syntax, and language development, and I can help you write more clearly, concisely, and effectively. Whether you're writing a blog post, a paper, or a short story, I'm here to offer suggestions for improvement and help you achieve your writing goals.\"}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hugging Face Inference Providers\n",
    "A Hugging Face Inference Provider is a service that runs AI models (like language, vision, or audio) and returns results via an API or cloud endpoint."
   ],
   "id": "47c9d7b1c3df2f53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:19:26.796046Z",
     "start_time": "2025-08-30T09:19:26.786935Z"
    }
   },
   "cell_type": "code",
   "source": "# You need to have a .tokens",
   "id": "16e942fe821f75c3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:19:29.602091Z",
     "start_time": "2025-08-30T09:19:28.586053Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install huggingface_hub",
   "id": "feec492c1f904b38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (0.34.4)\r\n",
      "Requirement already satisfied: filelock in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (3.19.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (2025.7.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from huggingface_hub) (1.1.9)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->huggingface_hub) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.8.3)\r\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:19:55.962394Z",
     "start_time": "2025-08-30T09:19:36.228380Z"
    }
   },
   "cell_type": "code",
   "source": "!hf auth login",
   "id": "c6be38d5ece03a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\r\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\r\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\r\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\r\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\r\n",
      "\r\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\r\n",
      "Enter your token (input will not be visible): Traceback (most recent call last):\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/bin/hf\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/cli/hf.py\", line 59, in main\r\n",
      "    service.run()\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/cli/auth.py\", line 126, in run\r\n",
      "    login(\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 130, in login\r\n",
      "    interpreter_login(new_session=new_session)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 287, in interpreter_login\r\n",
      "    token = getpass(\"Enter your token (input will not be visible): \")\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/getpass.py\", line 77, in unix_getpass\r\n",
      "    passwd = _raw_input(prompt, stream, input=input)\r\n",
      "  File \"/Users/octamarina/miniconda3/envs/AiEngineering/lib/python3.10/getpass.py\", line 146, in _raw_input\r\n",
      "    line = input.readline()\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "More on this [doc](https://huggingface.co/docs/inference-providers/en/index)",
   "id": "5d9865db34ba8e02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T09:23:27.570332Z",
     "start_time": "2025-08-30T09:23:15.189729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-V3-0324\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many 'G's in 'huggingface'?\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ],
   "id": "9039b7766afc0e87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content='Alright, let\\'s tackle the problem: **How many \\'G\\'s are in the word \\'huggingface\\'?**\\n\\n### Understanding the Problem\\nFirst, I need to determine how many times the letter \\'G\\' (both uppercase and lowercase, but in this case, it\\'s all lowercase) appears in the word \"huggingface.\" \\n\\n### Breaking Down the Word\\nLet\\'s write out the word and look at each letter one by one:\\n\\nThe word is: h u g g i n g f a c e\\n\\nNow, let\\'s list the letters with their positions to keep track:\\n\\n1. h\\n2. u\\n3. g\\n4. g\\n5. i\\n6. n\\n7. g\\n8. f\\n9. a\\n10. c\\n11. e\\n\\n### Counting the \\'G\\'s\\nNow, let\\'s go through each letter and count how many times \\'g\\' appears:\\n\\n1. h - not a g\\n2. u - not a g\\n3. g - this is the 1st g\\n4. g - this is the 2nd g\\n5. i - not a g\\n6. n - not a g\\n7. g - this is the 3rd g\\n8. f - not a g\\n9. a - not a g\\n10. c - not a g\\n11. e - not a g\\n\\n### Verifying\\nLet me recount to ensure I didn\\'t miss anything:\\n\\n- The 3rd letter: g (1)\\n- The 4th letter: g (2)\\n- The 7th letter: g (3)\\n\\nNo other letters are \\'g\\'s. \\n\\n### Potential Pitfalls\\nSometimes, it\\'s easy to overlook letters, especially if they\\'re repeated or if the word is long. To avoid missing any, numbering each letter as I did helps ensure each one is checked. Also, making sure that both uppercase and lowercase are considered if the word had any uppercase letters, but in \"huggingface,\" all letters are lowercase.\\n\\n### Final Count\\nAfter carefully reviewing each letter, the letter \\'g\\' appears **3 times** in \"huggingface.\"\\n\\n### Conclusion\\nAfter systematically going through each letter in \"huggingface,\" I\\'ve determined that the letter \\'g\\' appears **three times**.\\n\\n**Answer:** There are **3 \\'G\\'s** in \\'huggingface\\'.', tool_call_id=None, tool_calls=[])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "More pipelines examples [here](https://huggingface.co/learn/llm-course/en/chapter1/3)",
   "id": "fffecfd15c5a91f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8699e9fb6894f473"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
